# ğŸš€ Data Lake Stack com Docker: Apache Airflow, Spark e MinIO

Este projeto configura um ambiente completo para pipelines de dados usando Docker Compose com:

- **Apache Airflow** (orquestraÃ§Ã£o de workflows)
- **Apache Spark** (processamento distribuÃ­do)
- **MinIO** (armazenamento S3 compatÃ­vel)
- **PostgreSQL** (banco para o Airflow)

---

## ğŸ“¦ PrÃ©-requisitos

- Docker instalado: [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)
- Docker Compose instalado (vem junto com o Docker Desktop)
- Para inicializar digite no terminal docker-compose up --build --scale spark-worker=3 -d

---

## ğŸ“ Estrutura do Projeto
